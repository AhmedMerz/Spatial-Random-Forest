{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import os                                                 # set current working directory \n",
    "import sys                                                # enable/disable some outputs for clarity\n",
    "import numpy as np                                        # arrays and matrix math\n",
    "import pandas as pd                                       # DataFrames\n",
    "import matplotlib.pyplot as plt                           # plotting\n",
    "import geostatspy.geostats as geostats                    # synthetic data generation using Sequential Gaussian Simulation\n",
    "import geostatspy.GSLIB as GSLIB                          # synthetic data generation using Sequential Gaussian Simulation\n",
    "import random                                             # random number generation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler          # standard normalization of data\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "cmap = plt.cm.inferno                                     # color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable printing\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Enable Printing\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "# Benchmark generator subroutine. Uses SGSIM and cokriging to generate multi-feature simulations.\n",
    "def benchmark_generator(corrs, df, hmaj, hmin, num_of_features, seed, x_str='X', y_str='Y', feature_str='Porosity'):\n",
    "    '''Benchmark data generator. Generates num_of_features amount of features. Consequently, corrs array should be the same size\n",
    "    and the first element should be 0\n",
    "    '''\n",
    "    x, y = np.indices((100,100))\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    dataframe = pd.DataFrame({'x':x, 'y':y})\n",
    "    krig_arr = [0] + [4 for n in range(num_of_features-1)] # we need the first ktype to be 0 (regular kriging) and the rest to be 4 (cokriging)\n",
    "    sec_first = 0\n",
    "    sims = []\n",
    "    for i in range(num_of_features):\n",
    "        vario = GSLIB.make_variogram(nug=0.0,nst=1,it1=1,cc1=1.0,azi1=0.0,hmaj1=hmaj,hmin1=hmin)\n",
    "        sim_sk = geostats.sgsim(df,x_str,y_str,feature_str,wcol=-1,scol=-1,tmin=tmin,tmax=tmax,itrans=1,ismooth=0,dftrans=0,tcol=0,\n",
    "            twtcol=0,zmin=0.0,zmax=0.3,ltail=1,ltpar=0.0,utail=1,utpar=0.3,nsim=1,\n",
    "            nx=nx,xmn=xmn,xsiz=xsiz,ny=ny,ymn=ymn,ysiz=ysiz,seed=seed+i,\n",
    "            ndmin=ndmin,ndmax=ndmax,nodmax=20,mults=1,nmult=3,noct=-1,radius=radius,radius1=100000,sang1=0,\n",
    "            mxctx=81,mxcty=81,ktype=krig_arr[i],colocorr=corrs[i],sec_map=sec_first,vario=vario)\n",
    "        sim_sk = GSLIB.affine(sim_sk,0.0,1.0) # correct the mean and variance\n",
    "        sims.append(sim_sk)\n",
    "        sim_flat = sim_sk.flatten()\n",
    "        dataframe['feature' + str(i)] = sim_flat\n",
    "        if(i==0):\n",
    "            sec_first = sim_sk\n",
    "    \n",
    "    return sims, dataframe\n",
    "\n",
    "# Variogram plot subroutine\n",
    "def vargplot(feature,lags,gamma_maj,gamma_min,npps_maj,npps_min,vmodel,azi,atol,sill, save=None):     # plot the variogram\n",
    "    index_maj,lags_maj,gmod_maj,cov_maj,ro_maj = geostats.vmodel(nlag=100,xlag=10,azm=azi,vario=vmodel);\n",
    "    index_min,lags_min,gmod_min,cov_min,ro_min = geostats.vmodel(nlag=100,xlag=10,azm=azi+90.0,vario=vmodel);\n",
    "    \n",
    "    plt.scatter(lags,gamma_maj,color = 'black',s = npps_maj*0.01,label = 'Major Azimuth ' +str(azi), alpha = 0.8)\n",
    "    #plt.plot(lags_maj,gmod_maj,color = 'black')\n",
    "    plt.scatter(lags,gamma_min,color = 'red',s = npps_min*0.01,label = 'Minor Azimuth ' +str(azi+90.0), alpha = 0.8)\n",
    "    #plt.plot(lags_min,gmod_min,color = 'red')\n",
    "    plt.plot([0,2000],[sill,sill],color = 'black')\n",
    "    plt.xlabel(r'Lag Distance $\\bf(h)$, (m)')\n",
    "    plt.ylabel(r'$\\gamma \\bf(h)$')\n",
    "    if atol < 90.0:\n",
    "        plt.title('Directional ' + feature + ' Variogram')\n",
    "    else: \n",
    "        plt.title('Omni Directional NSCORE ' + feature + ' Variogram')\n",
    "    plt.xlim([0,10000]); #plt.ylim([0,1.8])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(visible=True, which='major', color='black', linestyle='-')\n",
    "    plt.grid(visible=True, which='minor', color='gray', linestyle='--')\n",
    "    plt.minorticks_on()\n",
    "    if(save!=None):\n",
    "        plt.savefig(save + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Facies</th>\n",
       "      <th>Porosity</th>\n",
       "      <th>Perm</th>\n",
       "      <th>AI</th>\n",
       "      <th>logPerm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120235</td>\n",
       "      <td>65.486859</td>\n",
       "      <td>4926.975019</td>\n",
       "      <td>4.181849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X      Y  Facies  Porosity       Perm           AI   logPerm\n",
       "0  500.0  500.0     1.0  0.120235  65.486859  4926.975019  4.181849"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking one point from an existing dataset to create our realizations.\n",
    "# This way, we are in a way building 'unconditional simulations'\n",
    "seed = 73703 # Setting a random seed\n",
    "df_orig = pd.read_csv(r\"https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/sample_data_MV_biased.csv\") # from Dr. Pyrcz's GitHub repo\n",
    "df_orig = df_orig.sample(50, random_state=seed)                     # extract 50 samples\n",
    "df_orig = df_orig.reset_index()                                     # reset the record index \n",
    "df_orig = df_orig.drop(['index','Unnamed: 0'],axis=1)               # remove extra columns in DataFrame\n",
    "df_orig['logPerm'] = np.log(df_orig['Perm'].values)                 # calculate the log of permeability\n",
    "#df_orig['X'] = df_orig['X'] + 9999999.9\n",
    "df_orig = df_orig.iloc[:1]\n",
    "df_orig.iloc[0,0] = 500.0\n",
    "df_orig.describe()  # summary statistics \n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random cases\n",
    "random.seed(73703)\n",
    "num_of_cases = 50\n",
    "cases = []\n",
    "while len(cases) < num_of_cases:\n",
    "    case = [random.randint(30, 50) * 10, random.randint(10, 20) * 10]\n",
    "    if case not in cases:\n",
    "        cases.append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the user wants to proceed the generation from a certain point in cases, the variable\n",
    "# proceed_from_idx could be changed from 1 to anything.\n",
    "proceed_from_idx = 1\n",
    "cases = cases[proceed_from_idx-1:]\n",
    "\n",
    "# Setting correlations and other necessary parameters for data generation\n",
    "corrs = [random.choice([random.uniform(-0.5, -0.01), random.uniform(0.01, 0.5)]) for _ in range(13)]\n",
    "num_of_features = len(corrs)\n",
    "nx = 100; ny = 100; xsiz = 10.0; ysiz = 10.0; xmn = 5.0; ymn = 5.0; nxdis = 1; nydis = 1\n",
    "ndmin = 0; ndmax = 1000; radius = 10000; skmean = 0\n",
    "tmin = -9999; tmax = 9999\n",
    "\n",
    "# Setting noise percentages and variances\n",
    "percentages = np.array([0, 10, 20, 30])\n",
    "noise_vars = (percentages * 100) / (100 - percentages) / 100\n",
    "\n",
    "# Setting random seed\n",
    "np.random.seed(73703)\n",
    "\n",
    "# Initializing the folder creation if the code is run for the first time (no dataset folders)\n",
    "if not os.path.exists('dataset'):\n",
    "    os.mkdir('dataset')\n",
    "\n",
    "\n",
    "        \n",
    "if not os.path.exists('dataset/vardump/noadhere'):\n",
    "    os.mkdir('dataset/vardump/noadhere')\n",
    "\n",
    "# Iterating for each case\n",
    "for case in cases:\n",
    "    # Setting the major and minor variogram ranges\n",
    "    hmaj, hmin = case[0], case[1]\n",
    "    \n",
    "    # Building the variogram using GSLIB\n",
    "    vario = GSLIB.make_variogram(nug=0.0,nst=1,it1=1,cc1=1.0,azi1=0.0,hmaj1=hmaj,hmin1=hmin)\n",
    "    \n",
    "\n",
    "    # SGSIM routine, we store the simulations in sims and the resultant dataframe in alpha\n",
    "    sims, alpha = benchmark_generator(corrs, df_orig, hmaj, hmin, 13, 73703) \n",
    "  \n",
    "  \n",
    "    \n",
    "    # The resulting dataframe is for each pixel. We would like to\n",
    "    # Scale it by 100, so that it represents an area of 10000x10000,\n",
    "    # Which is more realistic for geoscientific applications\n",
    "    alpha['x'] = alpha['x'] * 100\n",
    "    alpha['y'] = alpha['y'] * 100\n",
    "    \n",
    "    # Setting the name tag\n",
    "    name = str(hmaj*10) + '_' + str(hmin*10)\n",
    "    \n",
    "    df = alpha.copy() # Default is deep copy\n",
    "    \n",
    "    #### Checking if the simulation adheres to variogram\n",
    "    # This is necessary because sometimes artefacts might happen during the simulation,\n",
    "    # Resulting in simulations that does not preserve the variogram information,\n",
    "    # Hence would be erroneous to use in n_eff workflow\n",
    "\n",
    "\n",
    "  \n",
    "    features = list(df.columns[2:])\n",
    "    for idx, var in enumerate(noise_vars):\n",
    "        noise_lvl_str = str(percentages[idx])\n",
    "        for feature in features:\n",
    "            data = df[feature].values\n",
    "            noise = np.random.normal(0, var**0.5, data.shape[0])\n",
    "            df[feature] = StandardScaler().fit_transform((df[feature] + noise).values.reshape(-1, 1))\n",
    "        if not os.path.exists('dataset/'+ name + '_' + noise_lvl_str):\n",
    "            os.mkdir('dataset/'+ name + '_' + noise_lvl_str)\n",
    "        df.to_csv('dataset/'+ name + '_' + noise_lvl_str + '/' + name + '_' + noise_lvl_str +  '.csv', index=False)\n",
    "\n",
    "    clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
